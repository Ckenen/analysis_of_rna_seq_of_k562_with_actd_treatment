{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06a505f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T04:11:24.414252Z",
     "start_time": "2023-10-12T04:11:23.881124Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pyBioInfo.IO.File import GtfFile, GtfTranscriptBuilder\n",
    "from pyBioInfo.Utils import BlockTools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0035c45",
   "metadata": {},
   "source": [
    "# Make introns.bed.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dc4db69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T03:01:03.802886Z",
     "start_time": "2023-10-12T02:57:14.784394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All introns: 1307815\n",
      "Uniq introns: 395195\n"
     ]
    }
   ],
   "source": [
    "f_gtf = \"/home/chenzonggui/species/homo_sapiens/GRCh38.p13/gencode.v39.annotation.sorted.gtf.gz\"\n",
    "\n",
    "with GtfFile(f_gtf) as f:\n",
    "    records = [x for x in f]\n",
    "transcripts = list(GtfTranscriptBuilder(records))\n",
    "\n",
    "introns = []\n",
    "for t in transcripts:\n",
    "    for start, end in BlockTools.gaps(t.blocks):\n",
    "        introns.append((t.chrom, start, end, \"Intron\", \".\", t.strand))\n",
    "print(\"All introns:\", len(introns))\n",
    "\n",
    "introns = set(introns)\n",
    "print(\"Uniq introns:\", len(introns))\n",
    "\n",
    "with open(\"results/introns/introns.bed\", \"w+\") as fw:\n",
    "    for row in sorted(introns):\n",
    "        fw.write(\"\\t\".join(map(str, row)) + \"\\n\")\n",
    "        \n",
    "cmd = \"bgzip -f results/introns/introns.bed\"\n",
    "assert os.system(cmd) == 0\n",
    "cmd = \"tabix -p bed -f results/introns/introns.bed.gz\"\n",
    "assert os.system(cmd) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4976a64f",
   "metadata": {},
   "source": [
    "# Normalized intron quatification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "941fbfbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T04:10:32.322116Z",
     "start_time": "2023-10-12T04:10:12.930566Z"
    }
   },
   "outputs": [],
   "source": [
    "dates = [\"20221128\", \"20221205\"]\n",
    "\n",
    "samples = [\"0h-1\", \"0h-2\", \"3h-1\", \"3h-2\", \"6h-1\", \"6h-2\"]\n",
    "\n",
    "for date in dates:\n",
    "\n",
    "    factors = json.load(open(\"results/halflife/conversion_factors.%s.json\" % date))\n",
    "\n",
    "    paths = [\n",
    "        \"results/introns/counts/%s_K562_Actd_0h_rep1.tsv\" % date,\n",
    "        \"results/introns/counts/%s_K562_Actd_0h_rep2.tsv\" % date,\n",
    "        \"results/introns/counts/%s_K562_Actd_3h_rep1.tsv\" % date,\n",
    "        \"results/introns/counts/%s_K562_Actd_3h_rep2.tsv\" % date,\n",
    "        \"results/introns/counts/%s_K562_Actd_6h_rep1.tsv\" % date,\n",
    "        \"results/introns/counts/%s_K562_Actd_6h_rep2.tsv\" % date,\n",
    "    ]\n",
    "    \n",
    "    array = []\n",
    "    for sample, path in zip(samples, paths):\n",
    "        d = pd.read_csv(path, sep=\"\\t\", header=None)\n",
    "        d.columns = [\"Chrom\", \"Start\", \"End\", \"Name\", \"Count\", \"Strand\"]\n",
    "        s = d[\"Count\"]\n",
    "        s.name = sample\n",
    "        array.append(s)\n",
    "    dat = pd.concat(array, axis=1)\n",
    "    dat = pd.concat([d[[\"Chrom\", \"Start\", \"End\", \"Strand\"]], dat], axis=1)\n",
    "\n",
    "    dat.index = [\"%s_%s_%s\" % (chrom, start, end) for chrom, start, end in dat[[\"Chrom\", \"Start\", \"End\"]].values]\n",
    "    dat.index.name = \"ID\"\n",
    "\n",
    "    for sample in samples:\n",
    "        x = factors[\"%s,%s\" % (sample, \"0h-1\")]\n",
    "        dat[\"%s_adj\" % sample] = dat[sample] * x\n",
    "    for sample in samples:\n",
    "        dat[\"%s_adj_p\" % sample] = dat[\"%s_adj\" % sample] / dat[[\"0h-1_adj\", \"0h-2_adj\"]].mean(axis=1)\n",
    "        \n",
    "    dat.to_csv(\"results/introns/normalized_counts.%s.tsv\" % date, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
